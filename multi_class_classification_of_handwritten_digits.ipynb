{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-class_classification_of_handwritten_digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "266KQvZoMxMv",
        "6sfw3LH0Oycm",
        "copyright-notice"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jie786389209/ML/blob/master/multi_class_classification_of_handwritten_digits.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "copyright-notice",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "copyright-notice2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPa95uXvcpcn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " # 使用神经网络对手写数字进行分类"
      ]
    },
    {
      "metadata": {
        "id": "Fdpn8b90u8Tp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ![img](https://www.tensorflow.org/versions/r0.11/images/MNIST.png)"
      ]
    },
    {
      "metadata": {
        "id": "c7HLCm66Cs2p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **学习目标：**\n",
        "  * 训练线性模型和神经网络，以对传统 [MNIST](http://yann.lecun.com/exdb/mnist/) 数据集中的手写数字进行分类\n",
        "  * 比较线性分类模型和神经网络分类模型的效果\n",
        "  * 可视化神经网络隐藏层的权重"
      ]
    },
    {
      "metadata": {
        "id": "HSEh-gNdu8T0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 我们的目标是将每个输入图片与正确的数字相对应。我们会创建一个包含几个隐藏层的神经网络，并在顶部放置一个归一化指数层，以选出最合适的类别。"
      ]
    },
    {
      "metadata": {
        "id": "2NMdE1b-7UIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 设置\n",
        "\n",
        "首先，我们下载数据集、导入 TensorFlow 和其他实用工具，并将数据加载到 *Pandas* `DataFrame`。请注意，此数据是原始 MNIST 训练数据的样本；我们随机选择了 20000 行。"
      ]
    },
    {
      "metadata": {
        "id": "4LJ4SD8BWHeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "20bdec3f-49b2-4582-d902-faa96db61efd"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "mnist_dataframe = pd.read_csv(\n",
        "  \"https://dl.google.com/mlcc/mledu-datasets/mnist_train_small.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "# Use just the first 10,000 records for training/validation\n",
        "mnist_dataframe = mnist_dataframe.head(10000)\n",
        "\n",
        "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))\n",
        "mnist_dataframe.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4876</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3892</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5591</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3    4    5    6    7    8    9   ...   775  776  777  \\\n",
              "4876    4    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "3892    5    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "369     0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "1263    2    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "5591    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
              "\n",
              "      778  779  780  781  782  783  784  \n",
              "4876    0    0    0    0    0    0    0  \n",
              "3892    0    0    0    0    0    0    0  \n",
              "369     0    0    0    0    0    0    0  \n",
              "1263    0    0    0    0    0    0    0  \n",
              "5591    0    0    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "kg0-25p2mOi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 第一列中包含类别标签。其余列中包含特征值，每个像素对应一个特征值，有 `28×28=784` 个像素值，其中大部分像素值都为零；您也许需要花一分钟时间来确认它们不*全部*为零。"
      ]
    },
    {
      "metadata": {
        "id": "PQ7vuOwRCsZ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ![img](https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png)"
      ]
    },
    {
      "metadata": {
        "id": "dghlqJPIu8UM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 这些样本都是分辨率相对较低、对比度相对较高的手写数字图片。`0-9` 这十个数字中的每个可能出现的数字均由唯一的类别标签表示。因此，这是一个具有 10 个类别的多类别分类问题。\n",
        "\n",
        "现在，我们解析一下标签和特征，并查看几个样本。注意 `loc` 的使用，借助 `loc`，我们能够基于原来的位置抽出各列，因为此数据集中没有标题行。"
      ]
    },
    {
      "metadata": {
        "id": "JfFWWvMWDFrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_labels_and_features(dataset):\n",
        "  \"\"\"Extracts labels and features.\n",
        "  \n",
        "  This is a good place to scale or transform the features if needed.\n",
        "  \n",
        "  Args:\n",
        "    dataset: A Pandas `Dataframe`, containing the label on the first column and\n",
        "      monochrome pixel values on the remaining columns, in row major order.\n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      labels: A Pandas `Series`.\n",
        "      features: A Pandas `DataFrame`.\n",
        "  \"\"\"\n",
        "  labels = dataset[0]\n",
        "\n",
        "  # DataFrame.loc index ranges are inclusive at both ends.\n",
        "  features = dataset.loc[:,1:784]\n",
        "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
        "  features = features / 255\n",
        "\n",
        "  return labels, features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFY_-7vZu8UU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "666c952a-207e-45d9-e180-e2b857a2c271"
      },
      "cell_type": "code",
      "source": [
        "training_targets, training_examples = parse_labels_and_features(mnist_dataframe[:7500])\n",
        "training_examples.describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>7500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      1.0    1.0    0.8    0.2    1.0    0.2    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 7500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "4-Vgg-1zu8Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "cb84e05d-7374-482d-a676-b628a2ca107c"
      },
      "cell_type": "code",
      "source": [
        "validation_targets, validation_examples = parse_labels_and_features(mnist_dataframe[7500:10000])\n",
        "validation_examples.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>2500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1      2      3      4      5      6      7      8      9      10   \\\n",
              "count 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "       ...      775    776    777    778    779    780    781    782    783  \\\n",
              "count  ...   2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
              "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "max    ...      1.0    0.7    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "\n",
              "         784  \n",
              "count 2500.0  \n",
              "mean     0.0  \n",
              "std      0.0  \n",
              "min      0.0  \n",
              "25%      0.0  \n",
              "50%      0.0  \n",
              "75%      0.0  \n",
              "max      0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "wrnAI1v6u8Uh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 显示一个随机样本及其对应的标签。"
      ]
    },
    {
      "metadata": {
        "id": "s-euVJVtu8Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "6e3882b4-b9d6-4e83-8f22-4b288adf109e"
      },
      "cell_type": "code",
      "source": [
        "rand_example = np.random.choice(training_examples.index)\n",
        "_, ax = plt.subplots()\n",
        "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
        "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
        "ax.grid(False)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFXCAYAAAAro2x+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4irQBxQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7faae85099d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ScmYX7xdZMXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 任务 1：为 MNIST 构建线性模型\n",
        "\n",
        "首先，我们创建一个基准模型，作为比较对象。`LinearClassifier` 可提供一组 *k* 类一对多分类器，每个类别（共 *k* 个）对应一个分类器。\n",
        "\n",
        "您会发现，除了报告准确率和绘制对数损失函数随时间变化情况的曲线图之外，我们还展示了一个[**混淆矩阵**](https://en.wikipedia.org/wiki/Confusion_matrix)。混淆矩阵会显示错误分类为其他类别的类别。哪些数字相互之间容易混淆？\n",
        "\n",
        "另请注意，我们会使用 `log_loss` 函数跟踪模型的错误。不应将此函数与用于训练的 `LinearClassifier` 内部损失函数相混淆。"
      ]
    },
    {
      "metadata": {
        "id": "cpoVC4TSdw5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  \n",
        "  # There are 784 pixels in each image \n",
        "  return set([tf.feature_column.numeric_column('pixels', shape=784)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMmL89yGeTfz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 在本次练习中，我们会对训练和预测使用单独的输入函数，并将这些函数分别嵌套在 `create_training_input_fn()` 和 `create_predict_input_fn()` 中，这样一来，我们就可以调用这些函数，以返回相应的 `_input_fn`，并将其传递到 `.train()` 和 `.predict()` 调用。"
      ]
    },
    {
      "metadata": {
        "id": "OeS47Bmn5Ms2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
        "  \"\"\"A custom input_fn for sending MNIST data to the estimator for training.\n",
        "\n",
        "  Args:\n",
        "    features: The training features.\n",
        "    labels: The training labels.\n",
        "    batch_size: Batch size to use during training.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns batches of training features and labels during\n",
        "    training.\n",
        "  \"\"\"\n",
        "  def _input_fn(num_epochs=None, shuffle=True):\n",
        "    # Input pipelines are reset with each call to .train(). To ensure model\n",
        "    # gets a good sampling of data, even when steps is small, we \n",
        "    # shuffle all the data before creating the Dataset object\n",
        "    idx = np.random.permutation(features.index)\n",
        "    raw_features = {\"pixels\":features.reindex(idx)}\n",
        "    raw_targets = np.array(labels[idx])\n",
        "   \n",
        "    ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zoGWAoohrwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_predict_input_fn(features, labels, batch_size):\n",
        "  \"\"\"A custom input_fn for sending mnist data to the estimator for predictions.\n",
        "\n",
        "  Args:\n",
        "    features: The features to base predictions on.\n",
        "    labels: The labels of the prediction examples.\n",
        "\n",
        "  Returns:\n",
        "    A function that returns features and labels for predictions.\n",
        "  \"\"\"\n",
        "  def _input_fn():\n",
        "    raw_features = {\"pixels\": features.values}\n",
        "    raw_targets = np.array(labels)\n",
        "    \n",
        "    ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "        \n",
        "    # Return the next batch of data\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6DjSLZMu8Um",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, and a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `LinearClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create a LinearClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.LinearClassifier(\n",
        "      feature_columns=construct_feature_columns(),\n",
        "      n_classes=10,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.estimator.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class)\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItHIUyv2u8Ur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **花费 5 分钟的时间了解一下使用这种形式的线性模型时，准确率方面表现如何。在本次练习中，为自己设定限制，仅使用批量大小、学习速率和步数这三个超参数进行试验。**\n",
        "\n",
        "如果您从上述任何试验中得到的准确率约为 0.9，即可停止试验。"
      ]
    },
    {
      "metadata": {
        "id": "yaiIhIQqu8Uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "outputId": "d8374f8b-5911-4a0a-e7c0-f669717d1917"
      },
      "cell_type": "code",
      "source": [
        "classifier = train_linear_classification_model(\n",
        "             learning_rate=0.02,\n",
        "             steps=100,\n",
        "             batch_size=10,\n",
        "             training_examples=training_examples,\n",
        "             training_targets=training_targets,\n",
        "             validation_examples=validation_examples,\n",
        "             validation_targets=validation_targets)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "LogLoss error (on validation data):\n",
            "  period 00 : 17.23\n",
            "  period 01 : 9.60\n",
            "  period 02 : 9.86\n",
            "  period 03 : 8.62\n",
            "  period 04 : 7.52\n",
            "  period 05 : 6.52\n",
            "  period 06 : 6.42\n",
            "  period 07 : 5.84\n",
            "  period 08 : 5.97\n",
            "  period 09 : 5.32\n",
            "Model training finished.\n",
            "Final accuracy (on validation data): 0.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlbaIiIhJqLRFRERM4i+30oGZMYk2twAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7faadf030c90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFnCAYAAACM3c9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7faae0ab5d50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "266KQvZoMxMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### 解决方案\n",
        "\n",
        "点击下方即可查看一种可能的解决方案。"
      ]
    },
    {
      "metadata": {
        "id": "lRWcn24DM3qa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 以下是一组使准确率应该约为 0.9 的参数。"
      ]
    },
    {
      "metadata": {
        "id": "TGlBMrUoM1K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_ = train_linear_classification_model(\n",
        "    learning_rate=0.03,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk095OfpPdOx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 任务 2：使用神经网络替换线性分类器\n",
        "\n",
        "**使用 [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier) 替换上面的 LinearClassifier，并查找可实现 0.95 或更高准确率的参数组合。**\n",
        "\n",
        "您可能希望尝试 Dropout 等其他正则化方法。这些额外的正则化方法已记录在 `DNNClassifier` 类的注释中。"
      ]
    },
    {
      "metadata": {
        "id": "rm8P_Ttwu8U4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Replace the linear classifier with a neural network.\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOfmiSvqu8U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 获得出色的模型后，通过评估我们将在下面加载的测试数据进行仔细检查，确认您没有过拟合验证集。\n"
      ]
    },
    {
      "metadata": {
        "id": "evlB5ubzu8VJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://dl.google.com/mlcc/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDuLd2Hcu8VL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE: Calculate accuracy on the test set.\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6sfw3LH0Oycm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ### 解决方案\n",
        "\n",
        "点击下方即可查看可能的解决方案。"
      ]
    },
    {
      "metadata": {
        "id": "XatDGFKEO374",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 除了神经网络专用配置（例如隐藏单元的超参数）之外，以下代码与原始的 `LinearClassifer` 训练代码几乎完全相同。"
      ]
    },
    {
      "metadata": {
        "id": "kdNTx8jkPQUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn_classification_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a neural network classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, as well as a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `DNNClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  # Caution: input pipelines are reset with each call to train. \n",
        "  # If the number of steps is small, your model may never see most of the data.  \n",
        "  # So with multiple `.train` calls like this you may want to control the length \n",
        "  # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, \n",
        "  # or since it's in-memory data, shuffle all the data in the `input_fn`.\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
        "\n",
        "  # Create a DNNClassifier object.\n",
        "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.DNNClassifier(\n",
        "      feature_columns=feature_columns,\n",
        "      n_classes=10,\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss error (on validation data):\")\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class)\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZfzsTYGPPU8I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = train_nn_classification_model(\n",
        "    learning_rate=0.05,\n",
        "    steps=1000,\n",
        "    batch_size=30,\n",
        "    hidden_units=[100, 100],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXvrOgtUR-zD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 接下来，我们来验证测试集的准确率。"
      ]
    },
    {
      "metadata": {
        "id": "scQNpDePSFjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_test_dataframe = pd.read_csv(\n",
        "  \"https://dl.google.com/mlcc/mledu-datasets/mnist_test.csv\",\n",
        "  sep=\",\",\n",
        "  header=None)\n",
        "\n",
        "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
        "test_examples.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVaWpWKvSHmu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_test_input_fn = create_predict_input_fn(\n",
        "    test_examples, test_targets, batch_size=100)\n",
        "\n",
        "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
        "test_predictions = np.array([item['class_ids'][0] for item in test_predictions])\n",
        "  \n",
        "accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
        "print(\"Accuracy on test data: %0.2f\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WX2mQBAEcisO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## 任务 3：可视化第一个隐藏层的权重。\n",
        "\n",
        "我们来花几分钟时间看看模型的 `weights_` 属性，以深入探索我们的神经网络，并了解它学到了哪些规律。\n",
        "\n",
        "模型的输入层有 `784` 个权重，对应于 `28×28` 像素输入图片。第一个隐藏层将有 `784×N` 个权重，其中 `N` 指的是该层中的节点数。我们可以将这些权重重新变回 `28×28` 像素的图片，具体方法是将 `N` 个 `1×784` 权重数组*变形*为 `N` 个 `28×28` 大小数组。\n",
        "\n",
        "运行以下单元格，绘制权重曲线图。请注意，此单元格要求名为 \"classifier\" 的 `DNNClassifier` 已经过训练。"
      ]
    },
    {
      "metadata": {
        "id": "eUC0Z8nbafgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classifier.get_variable_names())\n",
        "\n",
        "weights0 = classifier.get_variable_value(\"dnn/hiddenlayer_0/kernel\")\n",
        "\n",
        "print(\"weights0 shape:\", weights0.shape)\n",
        "\n",
        "num_nodes = weights0.shape[1]\n",
        "num_rows = int(math.ceil(num_nodes / 10.0))\n",
        "fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))\n",
        "for coef, ax in zip(weights0.T, axes.ravel()):\n",
        "    # Weights in coef is reshaped from 1x784 to 28x28.\n",
        "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink)\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kL8MEhNgrx9N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 神经网络的第一个隐藏层应该会对一些级别特别低的特征进行建模，因此可视化权重可能只显示一些模糊的区域，也可能只显示数字的某几个部分。此外，您可能还会看到一些基本上是噪点（这些噪点要么不收敛，要么被更高的层忽略）的神经元。\n",
        "\n",
        "在迭代不同的次数后停止训练并查看效果，可能会发现有趣的结果。\n",
        "\n",
        "**分别用 10、100 和 1000 步训练分类器。然后重新运行此可视化。**\n",
        "\n",
        "您看到不同级别的收敛之间有哪些直观上的差异？"
      ]
    }
  ]
}